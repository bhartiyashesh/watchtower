---
phase: 02-object-detection
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - tests/test_object_detector.py
  - .gitignore
autonomous: true
requirements: [YOLO-01, YOLO-02, YOLO-03, YOLO-04, YOLO-05]

must_haves:
  truths:
    - "YOLO11n detects a person in a test image and returns a Detection with label='person'"
    - "Only relevant COCO classes (person, car, cat, dog, package) appear in detection results — irrelevant classes are filtered out"
    - "detect() is async and does not block the event loop — verified by concurrent heartbeat test"
    - "crop_person_bbox() returns JPEG bytes with dimensions matching the bounding box region, not the full frame"
    - "detections_to_dicts() produces the exact dict format EventStore.write_event() expects"
    - "Detection objects contain all required fields: label, confidence, bbox_x1, bbox_y1, bbox_x2, bbox_y2"
    - "Inference completes in under 5 seconds on macOS dev environment (smoke test for latency pattern)"
  artifacts:
    - path: "tests/test_object_detector.py"
      provides: "Comprehensive test suite for ObjectDetector, crop_person_bbox, detections_to_dicts"
      min_lines: 100
  key_links:
    - from: "tests/test_object_detector.py"
      to: "object_detector.py"
      via: "imports ObjectDetector, Detection, crop_person_bbox, detections_to_dicts, RELEVANT_CLASSES"
      pattern: "from object_detector import"
    - from: "tests/test_object_detector.py heartbeat test"
      to: "object_detector.py detect()"
      via: "asyncio.gather(heartbeat(), inference()) verifies event loop not blocked"
      pattern: "asyncio.gather"
---

<objective>
Create a comprehensive test suite for the ObjectDetector module covering all YOLO requirements.

Purpose: Prove that the ObjectDetector works correctly in isolation before Phase 3 wires it into the pipeline. Tests validate detection accuracy on a real YOLO model, non-blocking executor behavior, person crop dimensions, and EventStore format compatibility.

Output: tests/test_object_detector.py with passing tests for all YOLO-01 through YOLO-05 requirements

**NCNN benchmark deferral note:** ROADMAP success criterion 2 requires "YOLO inference completes in under 250ms per frame on Raspberry Pi 4 with NCNN model (benchmarked on actual hardware)." This cannot be validated on macOS development environment. The 250ms RPi 4 NCNN benchmark is deferred to deployment on actual RPi 4 hardware (Phase 2 deployment or Phase 3 integration testing on-device). This plan includes a development-environment latency smoke test (test_inference_completes_in_reasonable_time) that verifies the inference pattern works end-to-end and completes within 5 seconds on macOS, confirming the code path is functional even though absolute latency cannot be validated until on-device.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-object-detection/02-RESEARCH.md
@.planning/phases/02-object-detection/02-01-SUMMARY.md
@object_detector.py
@event_store.py
@tests/test_event_store.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ObjectDetector test suite with real YOLO inference tests</name>
  <files>tests/test_object_detector.py</files>
  <action>
Create tests/test_object_detector.py with the following test functions. Use pytest and pytest-asyncio (strict mode, matching Phase 1 test conventions from tests/test_event_store.py).

**Test fixture — generate a synthetic test image with a person-like shape:**

Create a pytest fixture `sample_frame_bytes` that generates a 640x480 RGB image using Pillow with a simple colored rectangle in the center (simulating a figure). Convert to JPEG bytes. This is used for model loading and basic inference tests. Note: YOLO may or may not detect a "person" in a synthetic rectangle — that is acceptable. The test validates that the ObjectDetector processes the image and returns a list (possibly empty) without errors.

Also create a fixture `detector` that instantiates `ObjectDetector("yolo11n.pt")` once per test module (scope="module") to avoid re-loading the model for every test. Use `yield` and call `detector.shutdown()` in teardown.

**Test functions to implement:**

1. `test_detector_loads_model` — Verify ObjectDetector.__init__ succeeds with "yolo11n.pt" and the model attribute is set. Assert `detector.model is not None` and `detector._executor is not None`.

2. `test_detect_returns_list_of_detections` — Call `await detector.detect(sample_frame_bytes)`. Assert the return type is `list`. If detections are returned, verify each element is a `Detection` instance with all expected fields (label, confidence, bbox_x1, bbox_y1, bbox_x2, bbox_y2).

3. `test_detection_labels_are_relevant_only` — Call `await detector.detect(sample_frame_bytes)`. For every Detection returned, assert `d.label in RELEVANT_CLASSES.values()` — no irrelevant COCO classes should appear.

4. `test_detection_confidence_above_threshold` — For every Detection returned, assert `d.confidence >= CONFIDENCE_THRESHOLD`.

5. `test_detection_bbox_coordinates_are_positive` — For every Detection returned, assert all bbox values are >= 0, and bbox_x2 > bbox_x1, bbox_y2 > bbox_y1.

6. `test_detect_empty_on_blank_image` — Create a solid white 640x480 image (no objects). Call `await detector.detect(white_bytes)`. Assert the result is an empty list (YOLO should not detect anything in a blank white frame).

7. `test_detect_handles_invalid_bytes` — Call `await detector.detect(b"not-an-image")`. Assert it returns an empty list without raising an exception (graceful error handling per _predict_sync's try/except).

8. `test_detect_is_non_blocking` (YOLO-03 verification) — Run a concurrent heartbeat test:
   - Create an async heartbeat coroutine that records timestamps every 100ms for 3 seconds using `asyncio.sleep(0.1)`.
   - Create an async inference coroutine that calls `await detector.detect(sample_frame_bytes)` 3 times.
   - Run both concurrently with `asyncio.gather(heartbeat(), inference())`.
   - After both complete, compute the max gap between consecutive heartbeat timestamps.
   - Assert the max gap is less than 500ms. If the executor is working correctly, heartbeat intervals should stay near 100ms even during inference. If inference blocked the loop, gaps would be 100-600ms+.
   - This directly validates YOLO-03.

9. `test_crop_person_bbox_returns_jpeg_bytes` — Create a 640x480 test image. Create a Detection with label="person" and a known bbox (e.g., x1=100, y1=50, x2=300, y2=400). Call `crop_person_bbox(frame_bytes, detection)`. Assert the result is not None, is bytes, and can be opened as a valid JPEG image via PIL. Assert the opened image dimensions approximately match the bbox dimensions (width ~200, height ~350).

10. `test_crop_person_bbox_clamps_to_image_bounds` — Create a Detection with bbox coordinates that exceed the image dimensions (e.g., bbox_x2=800 on a 640-wide image). Call `crop_person_bbox()`. Assert it returns bytes (not None) and the resulting crop dimensions are clamped to the image size.

11. `test_crop_person_bbox_degenerate_box_returns_none` — Create a Detection with bbox_x1 == bbox_x2 (zero-width box). Call `crop_person_bbox()`. Assert it returns None.

12. `test_crop_person_bbox_invalid_bytes_returns_none` — Call `crop_person_bbox(b"not-an-image", some_detection)`. Assert it returns None without raising.

13. `test_detections_to_dicts_format` — Create a list of 2 Detection objects with known values. Call `detections_to_dicts(detections)`. Assert the result is a list of dicts, each with exactly the keys: label, confidence, bbox_x1, bbox_y1, bbox_x2, bbox_y2. Assert the values match the input Detection fields. This validates compatibility with EventStore.write_event()'s detections parameter format.

14. `test_detections_to_dicts_empty_list` — Call `detections_to_dicts([])`. Assert it returns `[]`.

15. `test_relevant_classes_mapping` — Assert RELEVANT_CLASSES contains exactly 5 entries with the expected class IDs and labels: {0: "person", 2: "car", 15: "cat", 16: "dog", 28: "package"}.

16. `test_inference_completes_in_reasonable_time` (YOLO-02 dev smoke test) — Measures end-to-end detect() latency on macOS to confirm the inference pattern is functional:
   - Use `time.monotonic()` to measure elapsed time for a single `await detector.detect(sample_frame_bytes)` call.
   - Assert elapsed time is less than 5.0 seconds. On macOS with PyTorch (.pt) format, inference typically takes 100-500ms; this generous 5s ceiling just ensures the code path works end-to-end and does not hang or error silently.
   - Add a comment in the test: `# NOTE: ROADMAP success criterion 2 requires <250ms on RPi 4 with NCNN model.`
   - Add a comment: `# That benchmark is deferred to on-device testing — cannot validate on macOS dev environment.`
   - Add a comment: `# This test is a smoke test confirming the inference pattern completes successfully.`

**Test conventions (match Phase 1 patterns):**
- Use `@pytest.mark.asyncio` on all async tests (strict mode).
- Use descriptive assert messages where helpful.
- No shared state between tests except the module-scoped detector fixture.
- Import from object_detector: ObjectDetector, Detection, crop_person_bbox, detections_to_dicts, RELEVANT_CLASSES, CONFIDENCE_THRESHOLD.
  </action>
  <verify>
    <automated>cd /Users/yasheshbharti/Documents/experiments/Ring-Auth/files/smart-lock-system && source venv/bin/activate && python -m pytest tests/test_object_detector.py -v --tb=short 2>&1 | tail -30</automated>
    <manual>Review test output — all tests should pass. The non-blocking test (test_detect_is_non_blocking) confirms YOLO-03. The latency smoke test (test_inference_completes_in_reasonable_time) confirms the inference pattern works.</manual>
  </verify>
  <done>tests/test_object_detector.py exists with 16 test functions covering YOLO-01 through YOLO-05. All tests pass. The non-blocking test confirms detect() does not stall the event loop. The latency smoke test confirms inference completes in under 5 seconds on macOS. The crop test confirms person bbox crop dimensions match expected values. The detections_to_dicts test confirms EventStore format compatibility.</done>
</task>

<task type="auto">
  <name>Task 2: Run full test suite and verify no regressions</name>
  <files>.gitignore</files>
  <action>
Run the complete test suite (both Phase 1 EventStore tests and Phase 2 ObjectDetector tests) to confirm:

1. All existing Phase 1 tests still pass (no regressions from ultralytics install or any other changes).
2. All new Phase 2 tests pass.
3. Total test count is 14 (Phase 1) + 16 (Phase 2) = 30 tests passing.

Run: `python -m pytest tests/ -v --tb=short`

If any Phase 1 tests fail, investigate and fix. The most likely regression risk is a numpy version conflict between ultralytics and face-recognition/opencv-python — if this occurs, check `pip check` output and document the conflict.

Also verify the YOLO model file exists (yolo11n.pt should have been auto-downloaded by ultralytics on first use during testing):
- Check if `yolo11n.pt` exists in the project root.
- If it does, add `yolo11n.pt` to `.gitignore` (model weights should not be committed — they are ~6MB and downloadable).
- Also add `yolo11n_ncnn_model/` to `.gitignore` for when the NCNN export is done on RPi.
  </action>
  <verify>
    <automated>cd /Users/yasheshbharti/Documents/experiments/Ring-Auth/files/smart-lock-system && source venv/bin/activate && python -m pytest tests/ -v --tb=short 2>&1 | tail -35</automated>
    <manual>Confirm total test count is 30 (14 + 16) and all pass. Confirm yolo11n.pt and yolo11n_ncnn_model/ are in .gitignore.</manual>
  </verify>
  <done>Full test suite passes with 30 tests (14 Phase 1 + 16 Phase 2). No regressions. YOLO model files added to .gitignore. pip check shows no dependency conflicts.</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_object_detector.py -v` — all 16 tests pass
2. `python -m pytest tests/ -v` — all 30 tests pass (no regressions)
3. Non-blocking test confirms max heartbeat gap < 500ms during inference
4. Latency smoke test confirms detect() completes in under 5 seconds on macOS
5. Crop test confirms output image dimensions match bbox region
6. detections_to_dicts test confirms EventStore-compatible dict format
7. RELEVANT_CLASSES test confirms all 5 required labels present
8. Invalid input tests confirm graceful error handling (empty list, None)
</verification>

<success_criteria>
- tests/test_object_detector.py exists with 16 test functions
- All 16 Phase 2 tests pass
- All 14 Phase 1 tests still pass (no regressions)
- Non-blocking behavior proven by concurrent heartbeat test
- Inference latency smoke test passes (< 5s on macOS dev env)
- Person crop dimensions verified
- EventStore dict format compatibility verified
- YOLO model files in .gitignore
- NOTE: The 250ms RPi 4 NCNN benchmark (ROADMAP success criterion 2) is deferred to on-device testing and cannot be validated in this dev-environment plan
</success_criteria>

<output>
After completion, create `.planning/phases/02-object-detection/02-02-SUMMARY.md`
</output>
