---
phase: 03-pipeline-integration
plan: "02"
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - tests/test_pipeline.py
autonomous: true
requirements: [PIPE-01, PIPE-02, PIPE-03, PIPE-04]

must_haves:
  truths:
    - "FastAPI lifespan starts polling loop as asyncio.Task without asyncio.run()"
    - "Full pipeline writes event records with YOLO detections to EventStore"
    - "Face recognition runs on YOLO-cropped person bbox, not full frame"
    - "SwitchBot unlock triggers on face match with cooldown state tracked"
    - "Cooldown blocks second unlock within cooldown window"
    - "camera_id is populated (not NULL, not empty) on every event write"
    - "camera_id is configurable via CAMERA_ID environment variable"
  artifacts:
    - path: "tests/test_pipeline.py"
      provides: "Integration test suite for all PIPE requirements"
      min_lines: 200
      contains: "test_full_pipeline_motion_event"
  key_links:
    - from: "tests/test_pipeline.py"
      to: "main.py"
      via: "imports polling_loop and tests it with mocked Ring/SwitchBot and real EventStore/ObjectDetector"
      pattern: "from main import polling_loop"
    - from: "tests/test_pipeline.py"
      to: "app.py"
      via: "imports app and tests lifespan and health endpoint"
      pattern: "from app import app"
---

<objective>
Comprehensive test suite validating all four PIPE requirements end-to-end: FastAPI lifespan startup (PIPE-01), full pipeline flow (PIPE-02), unlock behavior preservation (PIPE-03), and camera_id population (PIPE-04).

Purpose: Prove that the pipeline integration from Plan 01 works correctly with real EventStore and ObjectDetector against mocked Ring, SwitchBot, and FaceRecognizer services. The test suite is the verification gate before Phase 3 can be marked complete.

Output: `tests/test_pipeline.py` with 8+ tests covering all PIPE requirement behaviors.
</objective>

<context>
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/03-pipeline-integration/03-RESEARCH.md
@.planning/phases/03-pipeline-integration/03-01-SUMMARY.md

Source files under test:
@app.py
@main.py
@config.py
@ring_client.py
@event_store.py
@object_detector.py

Test patterns to follow:
@tests/test_event_store.py
@tests/test_object_detector.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline test fixtures and PIPE-01 tests</name>
  <files>tests/test_pipeline.py</files>
  <action>
Create `tests/test_pipeline.py` with the following structure.

**Module docstring:**
```
Comprehensive test suite for Phase 3 Pipeline Integration.

Validates all PIPE requirements (PIPE-01 through PIPE-04):
  PIPE-01: FastAPI lifespan starts Ring polling as asyncio.Task
  PIPE-02: Full pipeline: Ring capture -> YOLO -> face recognition -> EventStore write
  PIPE-03: Unlock behavior preserved (face match -> SwitchBot -> cooldown)
  PIPE-04: camera_id populated on every event, configurable via env var

Mocking strategy:
  - RingClient: AsyncMock (wait_for_event, capture_frame, authenticate, stop)
  - SwitchBotClient: MagicMock (unlock — sync method dispatched via executor)
  - FaceRecognizer: MagicMock (identify — sync method dispatched via executor)
  - ObjectDetector: Real instance (module-scoped, same pattern as test_object_detector.py)
  - EventStore: Real instance in temp directory (same pattern as test_event_store.py)
```

**Imports:**
```python
import asyncio
import io
import os
import tempfile
import time
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
import pytest_asyncio
from PIL import Image

from app import app
from config import Config
from event_store import EventStore
from main import polling_loop
from object_detector import ObjectDetector
```

**Helper function — create synthetic JPEG frame with a detectable person-shaped region:**
```python
def make_test_frame(width: int = 640, height: int = 480) -> bytes:
    """Create a synthetic JPEG frame for testing."""
    img = Image.new("RGB", (width, height), color=(128, 128, 128))
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=85)
    return buf.getvalue()
```

**Fixtures:**

1. `store` (function-scoped async fixture) — same pattern as test_event_store.py:
   - Create temp directory, initialize EventStore, yield, close

2. `detector` (module-scoped fixture) — same pattern as test_object_detector.py:
   - `ObjectDetector("yolo11n.pt")`, yield, `shutdown()`
   - Module-scoped because YOLO model load is expensive (~2s)

3. `mock_ring` (function-scoped fixture):
   - Create `MagicMock(spec=["wait_for_event", "capture_frame", "authenticate", "stop", "doorbell"])`
   - Set `mock_ring.wait_for_event = AsyncMock()`
   - Set `mock_ring.capture_frame = AsyncMock()`
   - Set `mock_ring.authenticate = AsyncMock()`
   - Set `mock_ring.stop = AsyncMock()`
   - Return the mock

4. `mock_switchbot` (function-scoped fixture):
   - `MagicMock()` with `mock_switchbot.unlock = MagicMock(return_value=True)`
   - Return the mock

5. `mock_recognizer` (function-scoped fixture):
   - `MagicMock()` with `mock_recognizer.identify = MagicMock(return_value=None)`
   - Set `mock_recognizer.known_encodings = ["fake"]` (non-empty so lifespan doesn't warn)
   - Return the mock

**PIPE-01 Tests:**

`test_app_has_lifespan`:
- Import `app` from app module
- Assert `app.router.lifespan_context is not None`
- This confirms FastAPI app is configured with a lifespan context manager

`test_health_endpoint`:
- Use `httpx.AsyncClient` (from httpx, ships with fastapi[standard]) with `ASGITransport` to test:
```python
from httpx import AsyncClient, ASGITransport
```
- BUT: the lifespan requires real Ring auth which we cannot provide in tests. Instead, test that the health endpoint route exists on the app:
```python
routes = [r.path for r in app.routes]
assert "/health" in routes
```

`test_no_asyncio_run_in_source`:
- Read `app.py` and `main.py` as strings
- Assert `"asyncio.run("` not in either file
- This confirms PIPE-01's "no loop conflict" requirement
  </action>
  <verify>
    <automated>cd /Users/yasheshbharti/Documents/experiments/Ring-Auth/files/smart-lock-system && source venv/bin/activate && python -m pytest tests/test_pipeline.py::test_app_has_lifespan tests/test_pipeline.py::test_health_endpoint tests/test_pipeline.py::test_no_asyncio_run_in_source -x -q 2>&1 | tail -5</automated>
    <manual>Confirm test_pipeline.py file exists with fixtures and first 3 tests passing</manual>
  </verify>
  <done>tests/test_pipeline.py exists with fixtures (store, detector, mock_ring, mock_switchbot, mock_recognizer) and 3 passing PIPE-01 tests</done>
</task>

<task type="auto">
  <name>Task 2: Add PIPE-02, PIPE-03, and PIPE-04 pipeline integration tests</name>
  <files>tests/test_pipeline.py</files>
  <action>
Append the following tests to `tests/test_pipeline.py` (created in Task 1).

**PIPE-02 Tests — Full pipeline flow:**

`test_full_pipeline_motion_event` (async):
- Configure mock_ring.wait_for_event to return `(12345, "motion")` on first call, then raise `asyncio.CancelledError` on second call (so the loop exits after processing one event)
- Configure mock_ring.capture_frame to return `make_test_frame()` bytes
- Configure mock_recognizer.identify to return `None` (no face match — stranger event)
- Call `await polling_loop(mock_ring, mock_recognizer, mock_switchbot, detector, store)`
  - Wrap in try/except asyncio.CancelledError to catch the expected cancellation
- Verify: `events = await store.get_recent_events(limit=10)`
- Assert `len(events) == 1`
- Assert `events[0]["recording_id"] == "12345"`
- Assert `events[0]["event_type"] == "motion"`
- Assert `events[0]["person_name"] is None` (stranger)
- Assert `events[0]["thumbnail_path"] is not None` (thumbnail saved)

`test_pipeline_event_has_detections` (async):
- Same setup as test_full_pipeline_motion_event
- After pipeline runs, retrieve event: `event = await store.get_event(1)`
- Assert `event is not None`
- Assert `isinstance(event["detections"], list)`
- Note: With a synthetic gray frame, YOLO may detect 0 objects. That's acceptable — the test validates the pipeline WRITES detections (even if empty list). The key assertion is that the event record exists and the detections key is a list.

`test_pipeline_with_face_match` (async):
- Configure mock_ring.wait_for_event: first call returns `(99999, "motion")`, second call raises CancelledError
- Configure mock_ring.capture_frame: returns `make_test_frame()`
- Configure mock_recognizer.identify to return `"alice"`
- Run polling_loop (with try/except CancelledError)
- Verify: event = await store.get_event(1)
- Assert `event["person_name"] == "alice"`
- Assert `event["unlock_granted"] == 1` (SQLite integer boolean)
- Assert `event["door_action"] == "unlocked"`
- Assert `mock_switchbot.unlock.called` — SwitchBot.unlock() was invoked

**PIPE-03 Tests — Unlock behavior preservation:**

`test_unlock_behavior_preserved` (async):
- Same as test_pipeline_with_face_match but also verify:
- `mock_switchbot.unlock.call_count == 1`
- Event record has `door_action == "unlocked"` and `unlock_granted == 1`

`test_cooldown_blocks_repeat_unlock` (async):
- Configure mock_ring.wait_for_event to return events on first 2 calls, CancelledError on third:
  - Call 1: `(11111, "motion")`
  - Call 2: `(22222, "motion")` (second event within cooldown)
  - Call 3: raise CancelledError
- Configure mock_ring.capture_frame to return `make_test_frame()` every time
- Configure mock_recognizer.identify to return `"bob"` every time
- Set `Config.UNLOCK_COOLDOWN` to a high value (e.g., 9999) via monkeypatch or direct attribute set so the second event is within cooldown
- Run polling_loop
- Verify: `mock_switchbot.unlock.call_count == 1` (second event was skipped due to cooldown)
- Note: Only 1 event record should exist (the first one) because cooldown causes `continue` before EventStore write. OR if the implementation writes events even during cooldown, assert the second event has `unlock_granted == 0`.
- IMPORTANT: Read the actual main.py implementation carefully to determine where the cooldown `continue` is in the flow. The current research code shows cooldown check BEFORE frame capture, meaning no event record is written during cooldown. Verify this matches the implemented code.

**PIPE-04 Tests — camera_id:**

`test_camera_id_populated_on_every_event` (async):
- Run the pipeline once (same pattern as test_full_pipeline_motion_event)
- Retrieve event: `event = await store.get_event(1)`
- Assert `event["camera_id"] is not None`
- Assert `event["camera_id"] != ""`
- Assert `event["camera_id"] == "front_door"` (default Config.CAMERA_ID value)

`test_camera_id_from_config` (async):
- Temporarily set `Config.CAMERA_ID = "back_patio"` (use monkeypatch or direct attribute)
- Run the pipeline once
- Retrieve event
- Assert `event["camera_id"] == "back_patio"`
- Restore original value after test

**Implementation notes:**
- Every async test must have `@pytest.mark.asyncio` decorator (pytest-asyncio strict mode)
- Use the function-scoped `store` fixture (fresh temp DB per test)
- Use the module-scoped `detector` fixture (shared YOLO model)
- For cooldown test: the mock_ring.wait_for_event side_effect list controls how many events the loop processes before it raises CancelledError and exits
- For the `side_effect` pattern: `mock_ring.wait_for_event.side_effect = [(12345, "motion"), asyncio.CancelledError()]` — the second call triggers the CancelledError handler which re-raises
- The polling_loop has an `await asyncio.sleep(2)` when wait_for_event returns None. To avoid returning None, make sure the side_effect list only contains tuples and CancelledError, never None.
  </action>
  <verify>
    <automated>cd /Users/yasheshbharti/Documents/experiments/Ring-Auth/files/smart-lock-system && source venv/bin/activate && python -m pytest tests/test_pipeline.py -x -q 2>&1 | tail -10</automated>
    <manual>Verify all tests pass and cover PIPE-01 through PIPE-04</manual>
  </verify>
  <done>tests/test_pipeline.py has 8+ tests all passing, covering: FastAPI lifespan structure (PIPE-01), no asyncio.run in source (PIPE-01), full pipeline event flow (PIPE-02), event has detections list (PIPE-02), face match triggers unlock (PIPE-03), cooldown blocks repeat unlock (PIPE-03), camera_id populated (PIPE-04), camera_id configurable (PIPE-04)</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_pipeline.py -x -q` — all tests pass
2. `python -m pytest tests/ -x -q` — full suite (30 existing + new pipeline tests) all pass, no regressions
3. Each PIPE requirement has at least one test:
   - PIPE-01: test_app_has_lifespan, test_health_endpoint, test_no_asyncio_run_in_source
   - PIPE-02: test_full_pipeline_motion_event, test_pipeline_event_has_detections
   - PIPE-03: test_pipeline_with_face_match / test_unlock_behavior_preserved, test_cooldown_blocks_repeat_unlock
   - PIPE-04: test_camera_id_populated_on_every_event, test_camera_id_from_config
</verification>

<success_criteria>
- tests/test_pipeline.py exists with 8+ tests
- All tests pass individually and as a suite
- Full test suite (tests/) passes with no regressions
- Every PIPE requirement (PIPE-01 through PIPE-04) has at least one automated test
- Mocking strategy: Ring/SwitchBot/FaceRecognizer mocked, EventStore/ObjectDetector real
- Tests follow existing patterns: pytest-asyncio strict mode, temp directory isolation, module-scoped YOLO fixture
</success_criteria>

<output>
After completion, create `.planning/phases/03-pipeline-integration/03-02-SUMMARY.md`
</output>
